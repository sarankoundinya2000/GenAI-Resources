# Resources for NLP and Generative AI

Welcome to this curated list of helpful resources I've explored during my journey in NLP and generative AI. I'll keep adding more relevant resources as I go through this exciting journey. üöÄ

---

## **Word2Vec**
- [Illustrated Word2Vec by Jay Alammar](https://jalammar.github.io/illustrated-word2vec/) üåü
- Gensim: [Word2Vec Implementation](https://radimrehurek.com/gensim/models/word2vec.html)
#### **Word Embedding Techniques**
- Glove: [Global Vectors for Word Representation](https://nlp.stanford.edu/projects/glove/)
- FastText: [Efficient Word Representations](https://fasttext.cc/)

## **Zero-Shot Prompting**
- [Zero-shot prompting for the FLAN-T5 Foundation Model on Amazon SageMaker Jumpstart](https://aws.amazon.com/blogs/machine-learning/zero-shot-prompting-for-the-flan-t5-foundation-model-in-amazon-sagemaker-jumpstart/) üí°

## **Prompt Engineering**
- [EMNLP: Prompt Engineering is the New Feature Engineering](https://www.amazon.science/blog/emnlp-prompt-engineering-is-the-new-feature-engineering) ‚ú®
- [Learn Prompting - Prompt Injection](https://learnprompting.org/docs/prompt_hacking/injection)
- [IBM's Guide on Prompt Injection](https://www.ibm.com/topics/prompt-injection) üõ°Ô∏è

## **BLEU and ROUGE Scores**
- [Understanding BLEU and ROUGE Scores for NLP Evaluation](https://medium.com/@sthanikamsanthosh1994/understanding-bleu-and-rouge-score-for-nlp-evaluation-1ab334ecadcb) üìä

## **Fine-Tuning LLMs**
- [Practical Tips for Fine-Tuning LLMs by Sebastian Raschka](https://magazine.sebastianraschka.com/p/practical-tips-for-finetuning-llms) üîß

## **Generative AI for Business**
- [AWS Generative AI](https://aws.amazon.com/ai/generative-ai/?gclid=Cj0KCQjwh7K1BhCZARIsAKOrVqGhJk-4WN33Vvboqbx-6zrFDEJVRhE9uVyF4VFoenNKeX5kyuaxqRYaApwbEALw_wcB&trk=3ff624fa-338f-4424-8a4a-7d7616d2b922&sc_channel=ps&ef_id=Cj0KCQjwh7K1BhCZARIsAKOrVqGhJk-4WN33Vvboqbx-6zrFDEJVRhE9uVyF4VFoenNKeX5kyuaxqRYaApwbEALw_wcB:G:s&s_kwcid=AL!4422!3!686079219753!e!!g!!amazon%20generative%20ai!20901655886!158309130458) üè¢

## **Instruction Fine-Tuned Models**
- [Scaling Instruction Fine-Tuned Models (arXiv)](https://arxiv.org/pdf/2210.11416) üß†
- [Introducing FLAN: Fine-Tuned Lang Net by Google Research](https://research.google/blog/introducing-flan-more-generalizable-language-models-with-instruction-fine-tuning/)

## **LangChain**
- [LangChain Tutorials](https://smith.langchain.com/o/67d58871-a124-5999-9494-e491bccb1cc6/#) üõ†Ô∏è
- [LLM Chain in LangChain](https://python.langchain.com/v0.2/docs/tutorials/llm_chain/)

## **Chat Completion and APIs**
- [Philschmid's Chat Completion API Examples](https://philschmid.github.io/easyllm/examples/chat-completion-api/) üí¨
- [Groq Console Text Chat Completion](https://console.groq.com/docs/text-chat)

## **Building Custom LLMs**
- [Building LLMs for Production](https://medium.com/@marvin_thompson/text2sql-is-out-rag2sql-is-in-5fd160a004f0)
- [Best Book for LLMs](https://livebook.manning.com/book/build-a-large-language-model-from-scratch/welcome/v-8/) üìö
- [Llama.cpp Repository](https://github.com/ggerganov/llama.cpp) ü¶ô

## **Retrieval-Augmented Generation (RAG)**
- [Databricks - Train LLMs on Your Data](https://www.databricks.com/resources/ebook/train-llms-your-data?scid=7018Y000001Fi1CQAS&utm_medium=paid+search&utm_source=google&utm_campaign=17102589780&utm_adgroup=156370061468&utm_content=ebook&utm_offer=train-llms-your-data&utm_ad=702952416146&utm_term=retrieval%20augmented%20generation&gad_source=1&gclid=Cj0KCQjwtZK1BhDuARIsAAy2VzsSfHt28Fmgr2P0riwy97S5Y3ffvbUD-15ouUsHpBoZIH7IdhT8OqQaAmwbEALw_wcB)
- [Build a Book-Reading Bot with RAG](https://medium.com/@petrpan/llm-101-build-your-own-book-reading-bot-or-search-engine-with-llm-rag-21823684dfb2) üìñ

## **Quantization and Optimization**
- [A Visual Guide to Quantization](https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-quantization)

---
## **Additional Resources**
- [PyTorch Implementation of Transformers](https://nlp.seas.harvard.edu/2018/04/03/attention.html)
- [Speech and Language Processing by Jurafsky and Martin](https://web.stanford.edu/~jurafsky/slp3/)
- [NLP Lecture Series (30 Hours)](https://www.youtube.com/watch?v=mEsleV16qdo&t=31s)
- [Cohere NLP and Generative AI Platform](https://docs.cohere.com/docs/the-cohere-platform)
- [Vision Transformers (ViT) Paper](https://arxiv.org/pdf/2010.11929)
- [NVIDIA Self-Paced Training Courses](https://learn.nvidia.com/en-us/training/self-paced-courses)
- [Building LLMs Guide](https://hugobowne.github.io/hugo-blog/posts/building-llms/)
- [Generative AI Chatbot Demo](https://www.linkedin.com/feed/update/urn:li:activity:7212862386943197184/)
- [Microsoft's Generative AI for Beginners](https://github.com/microsoft/generative-ai-for-beginners)
- [Google's Courses on Generative AI, Transformers, and BERT](https://www.linkedin.com/feed/update/urn:li:activity:7094195109746900993/)
- [Deep Dives into AI: Lecture 1](https://www.youtube.com/watch?v=k2pD3k1485A)
- [Deep Dives into AI: Lecture 2](https://www.youtube.com/watch?v=NZbgduKl9Zk)
- [Amazon SageMaker Foundation Models](https://github.com/aws/amazon-sagemaker-examples/tree/main/introduction_to_amazon_algorithms/jumpstart-foundation-models)



This list is a work in progress, and I will keep updating it with more valuable resources. Stay tuned! üòä
